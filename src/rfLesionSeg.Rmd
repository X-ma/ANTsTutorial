---
title: "Multi-resolution voxel-wise neighborhood random forest (MRV-NRF) lesion segmentation"
author: "Brian B. Avants, Dorian Pustina, Nicholas J. Tustison"
date: "February 22, 2015"
output:
  beamer_presentation:
    colortheme: dolphin
    fonttheme: structurebold
    highlight: tango
    includes:
      in_header: mystyle.tex
    incremental: yes
    theme: AnnArbor
    toc: yes
  slidy_presentation:
    highlight: tango
    incremental: yes
---

# Lesion segmentation

## Background

We build on the [BRATS 2013 challenge](http://www.ncbi.nlm.nih.gov/pubmed/25494501) to segment areas of the brain that have been damaged by stroke.

## Simulation

We define a function that will help us simulate large, lateralized lesions on the fly.
```{r simfun}
library(ANTsR)
simLesion<-function(  img, s , w, thresh=0.01, mask=NA, myseed )
{
  set.seed(myseed)
  img<-iMath(img,"Normalize")
  if ( is.na(mask) ) mask<-getMask(img)
  i<-makeImage( dim(img) , rnorm( length(as.array(img))  ) )
  i[ mask==0 ]<-0
  ni<-smoothImage(i,s)
  ni[mask==0]<-0
  i<-thresholdImage(ni,thresh,Inf)
  i<-iMath(i,"GetLargestComponent")
  ti<-antsImageClone(i)
  i[i>0]<-ti[i>0]
  i<-smoothImage(i,w)
  i[ mask != 1  ] <- 0
  i[ 1:(dim(img)[1]/2), 1:(dim(img)[2]-1) ]<-0
  limg<-antsImageClone(img)*iMath(i,"Neg")
  return( list(limg=limg, lesion=i ) )
}
```


## Generate test data

Now let's apply this function to generate a test dataset.
```{r testsub}
ti<-antsImageRead( getANTsRData("r27") )
seg2<-kmeansSegmentation( ti, 3 )$segmentation
ll2<-simLesion( ti, 10, 6, myseed=919 ) # different sized lesion
seg2[ ll2$lesion > 0.5 & seg2 > 0.5 ]<-4
```

## Generate test data

Now let's apply this function to generate a test dataset.
```{r testsub2}
invisible( plot(ll2$limg) )
```


## Make training data

Create training data and map to the test subject.  Note that
a "real" application of this type would use cost function masking.  
But let's ignore that aspect of the problem here.

## Make training data

```{r runsim}
img<-antsImageRead( getANTsRData("r16") )
timg1<-antsRegistration(ti,img,typeofTransform="SyNCC")$warpedmovout
seg<-kmeansSegmentation( timg1, 3 )$segmentation
ll<-simLesion( timg1, 12, 5, myseed=1 )
seg[ ll$lesion > 0.5 & seg > 0.5 ]<-4
```


## Make training data

```{r runsim2}
invisible( plot(ll$limg) )
```

## Pseudo-ground truth

This gives us a subject with a "ground truth" segmentation.

Now we get a new subject and map to the space of the arbitrarily chosen reference space.

## Pseudo-ground truth

```{r runsim1}
img<-antsImageRead( getANTsRData("r30") , 2  )
timg1<-antsRegistration( ti, img, typeofTransform="SyNCC")$warpedmovout
seg1<-kmeansSegmentation( timg1, 3 )$segmentation
ll1<-simLesion( timg1, 9, 5,  myseed=2 ) # different sized lesion
seg1[ ll1$lesion > 0.5 & seg1 > 0.5 ]<-4
```


## Pseudo-ground truth

```{r runsim2}
invisible( plot( ll1$limg ) )
```


# The study

## Perform training step

Now use these to train a model.
```{r buildmodel}
rad<-c(1,1) # fast setting
mr<-c(4,2,1) # multi-res schedule, downsample by 4, then feed to level 2
rfm<-mrvnrfs( list(seg,seg1) , list(list(ll$limg), list(ll1$limg) ),
  seg, rad=rad, nsamples = 50, ntrees=1000, multiResSchedule=mr )
```


## Combine with additional training runs

```{r combiner,eval=FALSE}
for ( i in 1:2 )
  {
  newrflist<-list()
  temp<-mrvnrfs( list(seg,seg1) , list(list(ll$limg), list(ll1$limg) ),
    seg, rad=rad, nsamples = 50, ntrees=1000, multiResSchedule=mr )
  for ( k in 1:length( mr ) )
    if ( length( rfm$rflist[[k]]$classes  ) == 
         length( temp$rflist[[k]]$classes )   )
      newrflist[[k]]<-combine( rfm$rflist[[k]], temp$rflist[[k]] )
  rfm$rflist<-newrflist
  }
```

## Apply the model to new data

We apply the learned model to segment the new data.
```{r applymodel}
mmseg<-mrvnrfs.predict( rfm$rflist, list(list(ll2$limg)),
  seg, rad=rad, multiResSchedule=mr )
```

## Apply the model to new data
```{r vizmodel}
invisible( plot(mmseg$seg, window.img=c(0,max(mmseg$seg) ) ) )
```


# Evaluation

## Show ground truth

Here is the ground truth.
```{r gtseg}
invisible( plot( seg2, window.img=c(0,max(seg2) ) ) )
```


## Lesion probability 

Take a quick look at the lesion probability.
```{r vizprob}
invisible( plot( mmseg$probs[[1]][[ max(mmseg$seg)  ]] ) )
```


## Dice overlap 

Now we compute the overlap.
```{r eval}
dicenumer<-sum(  mmseg$seg == max(mmseg$seg) & seg2 == max(seg2) )
dicedenom<-sum( mmseg$seg == max(mmseg$seg) ) + sum( seg2 == max(seg2)  )
dice <- 2.0 * dicenumer / dicedenom
```

## Summary

The Dice overlap is `r dice`.  We might consider model selection
as well where we do a quick estimate of lesion size based on the
volume of left hemisphere csf.  Then build the model from
subjects that "match" with respect to the coarse amount of lesion.
